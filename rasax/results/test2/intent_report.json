{
  "dormitory": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10,
    "confused_with": {}
  },
  "criterias": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10,
    "confused_with": {}
  },
  "thank": {
    "precision": 0.8888888888888888,
    "recall": 0.8,
    "f1-score": 0.8421052631578948,
    "support": 10,
    "confused_with": {
      "greet": 1,
      "career_opportunities": 1
    }
  },
  "benchmark": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10,
    "confused_with": {}
  },
  "tuition": {
    "precision": 1.0,
    "recall": 0.9,
    "f1-score": 0.9473684210526316,
    "support": 10,
    "confused_with": {
      "curriculum": 1
    }
  },
  "career_opportunities": {
    "precision": 0.9090909090909091,
    "recall": 1.0,
    "f1-score": 0.9523809523809523,
    "support": 10,
    "confused_with": {}
  },
  "comparison_school": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10,
    "confused_with": {}
  },
  "facility": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 8,
    "confused_with": {}
  },
  "ask_name": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10,
    "confused_with": {}
  },
  "help": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10,
    "confused_with": {}
  },
  "consultation": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10,
    "confused_with": {}
  },
  "profile": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 5,
    "confused_with": {}
  },
  "review": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10,
    "confused_with": {}
  },
  "goodbye": {
    "precision": 1.0,
    "recall": 0.9,
    "f1-score": 0.9473684210526316,
    "support": 10,
    "confused_with": {
      "thank": 1
    }
  },
  "greet": {
    "precision": 0.9090909090909091,
    "recall": 1.0,
    "f1-score": 0.9523809523809523,
    "support": 10,
    "confused_with": {}
  },
  "curriculum": {
    "precision": 0.9,
    "recall": 1.0,
    "f1-score": 0.9473684210526316,
    "support": 9,
    "confused_with": {}
  },
  "accuracy": 0.9736842105263158,
  "macro avg": {
    "precision": 0.9754419191919192,
    "recall": 0.975,
    "f1-score": 0.9743107769423558,
    "support": 152
  },
  "weighted avg": {
    "precision": 0.974807283359915,
    "recall": 0.9736842105263158,
    "f1-score": 0.9733049729587124,
    "support": 152
  }
}